## Introduction
This is an experimental yet fully functional TensorFlow reimplementation of the word embedding algorithm Word2Vec by Mikolov *et al.*. This implementation supports both model architecture, **Skip-gram** and **Continuous Bag-of-words**, as well as both training algorithms, **Negative Sampling** and **Hierarchical Softmax**.

## Reference
1. T Mikolov, K Chen, G Corrado, J Dean - Efficient Estimation of Word Representations in Vector Space, ICLR 2013
2. T Mikolov, I Sutskever, K Chen, GS Corrado, J Dean - Distributed Representations of Words and Phrases and their Compositionality, NIPS 2013
3. Original implementation by Mikolov, https://code.google.com/archive/p/word2vec/
4. Gensim implementation by Radim Řehůřek, https://radimrehurek.com/gensim/models/word2vec.html
